import streamlit as st
import cv2
import numpy as np
import os
import joblib
import pandas as pd
import json
import time
import math
import torch
from ultralytics import YOLO
from streamlit_drawable_canvas import st_canvas
from PIL import Image

# ==============================================================================
# [í˜¸í™˜ì„± íŒ¨ì¹˜] Streamlit 1.32.0+ í˜¸í™˜
# ==============================================================================
import streamlit.elements.image as st_image

if not hasattr(st_image, 'original_image_to_url'):
    st_image.original_image_to_url = st_image.image_to_url


def simple_patch(image, width=None, clamp=False, channels="RGB", output_format="JPEG", image_id=None,
                 allow_emoji=False):
    return st_image.original_image_to_url(image, width, clamp, channels, output_format, image_id)


st_image.image_to_url = simple_patch

# --- [ì´ˆê¸° ì„¤ì •] ---
if not os.path.exists('videos'): os.makedirs('videos')
if not os.path.exists('settings'): os.makedirs('settings')


# --- [í•¨ìˆ˜] ì„¤ì • ê´€ë¦¬ ---
def load_settings(video_name):
    json_path = os.path.join('settings', f"{video_name}.json")
    default_settings = {
        'zones': [],
        'warning_distance': 30,
        'angle_threshold': 130,
        'hip_ratio': 0.2,
        'extension_threshold': 0.85,
        'detection_mode': 'Algorithm',
        'vis_options': {
            'alert_only': False, 'bbox': True, 'label': True,
            'skeleton': True, 'zones': True, 'wrist_dot': True,
            'text': True
        }
    }

    if os.path.exists(json_path):
        try:
            with open(json_path, 'r') as f:
                saved = json.load(f)
                # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
                if 'zones' in saved:
                    valid_zones = []
                    for z in saved['zones']:
                        if 'points' in z and len(z['points']) > 2:
                            valid_zones.append(z)
                    saved['zones'] = valid_zones

                for k, v in default_settings.items():
                    if k not in saved: saved[k] = v
                if 'vis_options' not in saved: saved['vis_options'] = default_settings['vis_options']
                return saved
        except:
            return default_settings
    return default_settings


def save_settings(video_name, settings):
    json_path = os.path.join('settings', f"{video_name}.json")
    with open(json_path, 'w') as f: json.dump(settings, f, indent=4)


# --- [í•¨ìˆ˜] ê³„ì‚° ë° ë¶„ì„ ---
def get_distance(p1, p2):
    return math.sqrt((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2)


def calculate_angle(a, b, c):
    a, b, c = np.array(a), np.array(b), np.array(c)
    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])
    angle = np.abs(radians * 180.0 / np.pi)
    if angle > 180.0: angle = 360 - angle
    return angle


def process_frame(frame, yolo_model, custom_model, settings):
    # ë¶„ì„ìš© ë¦¬ì‚¬ì´ì¦ˆ (800x600 ê³ ì •)
    frame = cv2.resize(frame, (800, 600))
    h, w, _ = frame.shape

    zones = settings['zones']
    warn_dist = settings['warning_distance']
    ang_th = settings['angle_threshold']
    hip_r = settings['hip_ratio']
    ext_th = settings['extension_threshold']
    mode = settings['detection_mode']
    vis = settings['vis_options']

    device = 0 if torch.cuda.is_available() else 'cpu'
    results = yolo_model(frame, verbose=False, conf=0.25, device=device)

    # ë°°ê²½ ìƒì„±
    if vis['alert_only']:
        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    else:
        if vis['skeleton']:
            annotated_frame = results[0].plot(boxes=False, probs=False)
            image = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
        else:
            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    global_is_danger = False
    global_is_warning = False

    # 1. êµ¬ì—­ ê·¸ë¦¬ê¸°
    active_polygons = []
    if vis['zones']:
        for i, z in enumerate(zones):
            if not z.get('active', True): continue

            # ì •ê·œí™” ì¢Œí‘œ(0~1) -> í”½ì…€ ì¢Œí‘œ
            pts = np.array(z['points']) * [w, h]
            pts = pts.astype(np.int32).reshape((-1, 1, 2))
            active_polygons.append(pts)

            # (1) ê²½ê³  ì˜ì—­ (ë…¸ë€ìƒ‰ íŒ½ì°½)
            if warn_dist > 0:
                mask = np.zeros((h, w), dtype=np.uint8)
                cv2.fillPoly(mask, [pts], 255)
                k_size = int(warn_dist * 2) + 1
                kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (k_size, k_size))
                expanded_mask = cv2.dilate(mask, kernel)
                contours, _ = cv2.findContours(expanded_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(image, contours, -1, (255, 255, 0), 2)

            # (2) ìœ„í—˜ ì˜ì—­ (ë¹¨ê°„ìƒ‰ ì‹¤ì„ )
            cv2.polylines(image, [pts], True, (255, 0, 0), 2)

            start_pt = tuple(pts[0][0])
            cv2.putText(image, f"#{i + 1}", (start_pt[0], start_pt[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0),
                        2)

    # 2. í¬ì¦ˆ ë¶„ì„
    if results[0].keypoints is not None and results[0].boxes is not None:
        keypoints_data = results[0].keypoints.data.cpu().numpy()
        boxes_data = results[0].boxes.data.cpu().numpy()

        for box_info, kps in zip(boxes_data, keypoints_data):
            bx1, by1, bx2, by2, b_conf, b_cls = box_info

            p_danger = False
            p_warning = False
            wrist_points = []

            arms = [{'side': 'Right', 's': 6, 'e': 8, 'w': 10, 'h': 12},
                    {'side': 'Left', 's': 5, 'e': 7, 'w': 9, 'h': 11}]

            for arm in arms:
                if len(kps) > arm['h'] and kps[arm['w']][2] >= 0.25:
                    s, e, wrist, hip = kps[arm['s']], kps[arm['e']], kps[arm['w']], kps[arm['h']]
                    wx, wy = int(wrist[0]), int(wrist[1])
                    sx, sy = int(s[0]), int(s[1])
                    ex, ey = int(e[0]), int(e[1])

                    has_hip = hip[2] > 0.25
                    hy = int(hip[1]) if has_hip else 0
                    safe_y = hy - (abs(hy - sy) * hip_r) if has_hip else 0
                    is_low = (wy > safe_y) if has_hip else False

                    angle = calculate_angle((sx, sy), (ex, ey), (wx, wy))
                    len_u = get_distance((sx, sy), (ex, ey))
                    len_l = get_distance((ex, ey), (wx, wy))
                    ext_r = (get_distance((sx, sy), (wx, wy)) / (len_u + len_l)) if (len_u + len_l) > 0 else 0

                    is_algo = (angle > ang_th) or (ext_r > ext_th)
                    is_ai = False
                    if mode in ['AI', 'Both'] and custom_model:
                        inp = pd.DataFrame(
                            [{'rw_x': wx / w, 'rw_y': wy / h, 're_x': ex / w, 're_y': ey / h, 'rs_x': sx / w,
                              'rs_y': sy / h}])
                        try:
                            is_ai = (custom_model.predict(inp)[0] == 1)
                        except:
                            pass

                    is_reach = is_algo if mode == 'Algorithm' else (is_ai if mode == 'AI' else (is_algo and is_ai))
                    if is_low: is_reach = False

                    # ì¶©ëŒ ì²´í¬
                    in_d = False
                    in_w = False

                    for poly_pts in active_polygons:
                        dist = cv2.pointPolygonTest(poly_pts, (wx, wy), True)
                        if dist >= 0:
                            in_d = True
                        elif dist >= -warn_dist:
                            in_w = True

                    if in_d:
                        p_danger = True
                    elif in_w and is_reach:
                        p_warning = True

                    wrist_points.append(
                        {'x': wx, 'y': wy, 'state': 'D' if in_d else ('W' if in_w and is_reach else 'S')})

            if p_danger: global_is_danger = True
            if p_warning: global_is_warning = True

            draw_box = True
            if vis['alert_only'] and not (p_danger or p_warning): draw_box = False

            if draw_box:
                color = (255, 0, 0) if p_danger else ((255, 165, 0) if p_warning else (0, 255, 0))
                if vis['bbox']:
                    cv2.rectangle(image, (int(bx1), int(by1)), (int(bx2), int(by2)), color, 2)
                    if vis['label']:
                        status = "TOUCH" if p_danger else ("REACH" if p_warning else "Safe")
                        cv2.putText(image, status, (int(bx1), int(by1) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)

                if vis['wrist_dot']:
                    for wp in wrist_points:
                        c = (0, 255, 0)
                        if wp['state'] == 'D':
                            c = (255, 0, 0)
                        elif wp['state'] == 'W':
                            c = (255, 165, 0)
                        cv2.circle(image, (wp['x'], wp['y']), 6, c, -1)

    # ìƒíƒœë°”
    if global_is_danger:
        bar, msg, tc = (255, 0, 0), "DANGER: TOUCH DETECTED", (255, 255, 255)
    elif global_is_warning:
        bar, msg, tc = (255, 165, 0), "WARNING: APPROACHING", (0, 0, 0)
    else:
        bar, msg, tc = (50, 50, 50), "SYSTEM: SAFE", (0, 255, 0)

    cv2.rectangle(image, (0, 0), (w, 40), bar, -1)
    cv2.putText(image, msg, (15, 28), cv2.FONT_HERSHEY_SIMPLEX, 0.8, tc, 2)

    return image


# ==============================================================================
# [ë©”ì¸ UI]
# ==============================================================================
st.set_page_config(layout="wide", page_title="AI ì „ì‹œí’ˆ ë³´í˜¸ ì‹œìŠ¤í…œ v3")
st.title("ğŸ›ï¸ AI ì „ì‹œí’ˆ ë³´í˜¸ ê´€ë¦¬ ì‹œìŠ¤í…œ")


# 1. ëª¨ë¸ ë¡œë“œ
@st.cache_resource
def get_models():
    try:
        yolo = YOLO('yolov8n-pose.pt')
        custom = joblib.load('model.pkl') if os.path.isfile('model.pkl') else None
        return yolo, custom
    except:
        return None, None


yolo_model, custom_model = get_models()

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸ“‚ íŒŒì¼ ê´€ë¦¬")
    up = st.file_uploader("ì˜ìƒ ì—…ë¡œë“œ", type=["mp4", "avi"])
    if up:
        p = os.path.join("videos", f"vid_{int(time.time())}.mp4")
        with open(p, "wb") as f: f.write(up.getbuffer())
        st.success("ì—…ë¡œë“œ ì™„ë£Œ")
        st.rerun()

    v_list = [f for f in os.listdir("videos") if f.endswith(('.mp4', '.avi'))]
    sel_v = st.selectbox("ì˜ìƒ ì„ íƒ", v_list) if v_list else None

if not sel_v or not yolo_model:
    st.warning("ì˜ìƒì„ ì„ íƒí•˜ê±°ë‚˜ ëª¨ë¸ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# ì„¤ì • ë¡œë“œ
video_path = os.path.join("videos", sel_v)
curr_settings = load_settings(sel_v)

left_col, right_col = st.columns([1, 1], gap="medium")

# ==========================================
# [ì™¼ìª½] ì„¤ì • íƒ­
# ==========================================
with left_col:
    tab1, tab2, tab3 = st.tabs(["ğŸ“ êµ¬ì—­ ê´€ë¦¬", "âš¡ ê°ë„ ì„¤ì •", "ğŸ‘ï¸ ì‹œê°í™” ì„¤ì •"])

    # --- [íƒ­ 1] êµ¬ì—­ ê´€ë¦¬ (í†µí•©ë¨) ---
    with tab1:
        # 1. ìº”ë²„ìŠ¤ ìƒíƒœ ê´€ë¦¬ (í¸ì§‘ vs ê·¸ë¦¬ê¸°)
        if 'draw_mode_state' not in st.session_state:
            st.session_state['draw_mode_state'] = 'transform'  # ê¸°ë³¸ì€ í¸ì§‘(ì´ë™/ìˆ˜ì •)
        if 'cv_key' not in st.session_state:
            st.session_state['cv_key'] = 0

        # 2. ë²„íŠ¼ ì»¨íŠ¸ë¡¤
        col_btn1, col_btn2 = st.columns([1, 1])
        with col_btn1:
            # ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ê·¸ë¦¬ê¸° ëª¨ë“œë¡œ ì „í™˜
            if st.button("â• ìƒˆ êµ¬ì—­ ê·¸ë¦¬ê¸°", use_container_width=True):
                st.session_state['draw_mode_state'] = 'polygon'
                st.session_state['cv_key'] += 1  # ìº”ë²„ìŠ¤ ë¦¬ë¡œë“œí•˜ì—¬ ëª¨ë“œ ì ìš©
                st.rerun()
        with col_btn2:
            if st.button("ğŸ—‘ï¸ ì „ì²´ ì‚­ì œ", use_container_width=True):
                curr_settings['zones'] = []
                save_settings(sel_v, curr_settings)
                st.session_state['draw_mode_state'] = 'transform'
                st.session_state['cv_key'] += 1
                st.rerun()

        # í˜„ì¬ ëª¨ë“œ ì•ˆë‚´
        if st.session_state['draw_mode_state'] == 'polygon':
            st.info("ğŸ–Œï¸ **ê·¸ë¦¬ê¸° ëª¨ë“œ**: ì ì„ ì°ì–´ ë‹¤ê°í˜•ì„ ì™„ì„±í•˜ì„¸ìš”. (ì™„ë£Œ í›„ ì•„ë˜ 'ì €ì¥' ë²„íŠ¼ í´ë¦­)")
        else:
            st.info("âœ‹ **í¸ì§‘ ëª¨ë“œ**: êµ¬ì—­ì„ ì„ íƒí•˜ì—¬ ì´ë™í•˜ê±°ë‚˜ í¬ê¸°ë¥¼ ì¡°ì ˆí•˜ì„¸ìš”.")

        # 3. ìº”ë²„ìŠ¤ ë°°ê²½ ë° í¬ê¸°
        cw, ch = 600, 450
        if 'canvas_bg' not in st.session_state or st.session_state.get('last_vid') != sel_v:
            cap = cv2.VideoCapture(video_path)
            ret, frame = cap.read()
            cap.release()
            if ret:
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                img_pil = Image.fromarray(frame)
                st.session_state['canvas_bg'] = img_pil.resize((cw, ch))
            else:
                st.session_state['canvas_bg'] = None
            st.session_state['last_vid'] = sel_v

        bg_resized = st.session_state['canvas_bg']

        # 4. ì´ˆê¸° ë°ì´í„° ìƒì„± (ì¢Œí‘œ ì˜¤ì°¨ ë³´ì • ë¡œì§ í¬í•¨)
        initial_drawing = {"version": "4.4.0", "objects": []}

        # ì €ì¥ëœ êµ¬ì—­ì„ ë¶ˆëŸ¬ì™€ì„œ Path ê°ì²´ë¡œ ìº”ë²„ìŠ¤ì— ë°°ì¹˜
        # ì£¼ì˜: initial_drawingì€ keyê°€ ë³€ê²½ë  ë•Œë§Œ ìº”ë²„ìŠ¤ì— ì ìš©ë¨
        for z in curr_settings['zones']:
            pts = z['points']
            if not pts: continue

            # ì •ê·œí™” -> í”½ì…€
            poly_pts = np.array(pts) * [cw, ch]

            # Bounding Box (ì™¼ìª½ ìƒë‹¨ ê¸°ì¤€ì ) ê³„ì‚°
            min_x = np.min(poly_pts[:, 0])
            min_y = np.min(poly_pts[:, 1])

            # Path ëª…ë ¹ì–´ (Bounding Box ê¸°ì¤€ ìƒëŒ€ ì¢Œí‘œ)
            path_cmds = []
            path_cmds.append(["M", poly_pts[0][0] - min_x, poly_pts[0][1] - min_y])
            for p in poly_pts[1:]:
                path_cmds.append(["L", p[0] - min_x, p[1] - min_y])
            path_cmds.append(["Z"])

            initial_drawing['objects'].append({
                "type": "path",
                "path": path_cmds,
                "fill": "rgba(255, 0, 0, 0.2)",
                "stroke": "red",
                "strokeWidth": 2,
                "left": min_x,  # ì‹¤ì œ ìœ„ì¹˜
                "top": min_y,  # ì‹¤ì œ ìœ„ì¹˜
                "originX": "left",
                "originY": "top"
            })

        # 5. ìº”ë²„ìŠ¤ ë Œë”ë§
        canvas_result = st_canvas(
            fill_color="rgba(255, 0, 0, 0.2)",
            stroke_color="red",
            stroke_width=2,
            background_image=bg_resized,
            update_streamlit=True,
            height=ch, width=cw,
            drawing_mode=st.session_state['draw_mode_state'],  # í˜„ì¬ ëª¨ë“œ ë°˜ì˜
            initial_drawing=initial_drawing,
            key=f"canvas_{st.session_state['cv_key']}"
        )

        # 6. ì €ì¥ ë° ì ìš© (í•µì‹¬ ì¢Œí‘œ ë³´ì • ë¡œì§)
        if st.button("ğŸ’¾ êµ¬ì—­ ì €ì¥ (ì ìš©)", use_container_width=True, type="primary"):
            new_zones = []
            if canvas_result.json_data and "objects" in canvas_result.json_data:
                for obj in canvas_result.json_data["objects"]:

                    # 1) ê³µí†µ ì†ì„± ì¶”ì¶œ
                    left = obj.get('left', 0)
                    top = obj.get('top', 0)
                    scaleX = obj.get('scaleX', 1)
                    scaleY = obj.get('scaleY', 1)
                    points = []

                    # 2) Path (ê¸°ì¡´ êµ¬ì—­) ì¢Œí‘œ ë³µì›
                    if obj["type"] == "path":
                        for cmd in obj["path"]:
                            if cmd[0] == 'M' or cmd[0] == 'L':
                                # PathëŠ” Bounding Box(left, top) ê¸°ì¤€ ìƒëŒ€ ì¢Œí‘œì„
                                rel_x = cmd[1]
                                rel_y = cmd[2]
                                # ì ˆëŒ€ ì¢Œí‘œ = Boxìœ„ì¹˜ + (ìƒëŒ€ì¢Œí‘œ * ë°°ìœ¨)
                                abs_x = left + (rel_x * scaleX)
                                abs_y = top + (rel_y * scaleY)
                                points.append([abs_x / cw, abs_y / ch])

                    # 3) Polygon (ìƒˆë¡œ ê·¸ë¦° êµ¬ì—­) ì¢Œí‘œ ë³µì›
                    elif obj["type"] == "polygon":
                        # Polygonë„ Fabric.js ë²„ì „ì— ë”°ë¼ offset ì²˜ë¦¬ê°€ í•„ìš”í•  ìˆ˜ ìˆìŒ.
                        # st_canvasì—ì„œëŠ” ë³´í†µ left/topì´ ë°”ìš´ë”©ë°•ìŠ¤ ì‹œì‘ì .
                        # pathOffset ë“±ì„ ê³ ë ¤í•´ì•¼ í•˜ì§€ë§Œ, ê°€ì¥ ì•ˆì „í•œ ë°©ë²•ì€ ì•„ë˜ì™€ ê°™ìŒ:

                        # points ë°°ì—´ ë‚´ë¶€ëŠ” ë³´í†µ (0,0) ê·¼ì²˜ì˜ ê°’ë“¤ì´ê±°ë‚˜ ìƒëŒ€ê°’
                        # í•˜ì§€ë§Œ Fabric ê°ì²´ëŠ” í•­ìƒ left, topì„ ê°€ì§.
                        for p in obj["points"]:
                            rel_x = p.get('x', 0)
                            rel_y = p.get('y', 0)

                            # ê³µì‹ ì ìš©
                            abs_x = left + (rel_x * scaleX)
                            abs_y = top + (rel_y * scaleY)

                            points.append([abs_x / cw, abs_y / ch])

                    if len(points) > 2:
                        new_zones.append({'points': points, 'active': True})

            # ë°ì´í„° ì €ì¥
            curr_settings['zones'] = new_zones
            save_settings(sel_v, curr_settings)

            # ì €ì¥ í›„ì—ëŠ” í•­ìƒ 'í¸ì§‘ ëª¨ë“œ'ë¡œ ë³µê·€ + ìº”ë²„ìŠ¤ ë¦¬ë¡œë“œ (ê·¸ë˜ì•¼ Pathë¡œ ë³€í™˜ë˜ì–´ ë³´ì„)
            st.session_state['draw_mode_state'] = 'transform'
            st.session_state['cv_key'] += 1
            st.rerun()

        # 7. ë¦¬ìŠ¤íŠ¸ ê´€ë¦¬ (ê¹œë¹¡ì„ ë°©ì§€ ì ìš©)
        st.markdown("---")
        st.write("ğŸ“‹ **êµ¬ì—­ ëª©ë¡**")

        if not curr_settings['zones']:
            st.caption("êµ¬ì—­ì´ ì—†ìŠµë‹ˆë‹¤. 'ìƒˆ êµ¬ì—­ ê·¸ë¦¬ê¸°'ë¥¼ ëˆŒëŸ¬ë³´ì„¸ìš”.")
        else:
            zones_to_keep = []
            delete_occurred = False

            for i, z in enumerate(curr_settings['zones']):
                c1, c2, c3 = st.columns([0.2, 0.6, 0.2])
                with c1:
                    st.write(f"#{i + 1}")
                with c2:
                    curr_act = z.get('active', True)
                    # í‚¤ë¥¼ ê³ ìœ í•˜ê²Œ ì£¼ì–´ ìƒíƒœ ìœ ì§€
                    new_act = st.toggle("í™œì„±", value=curr_act, key=f"ac_{i}")
                    if new_act != curr_act:
                        z['active'] = new_act
                        curr_settings['zones'][i] = z
                        save_settings(sel_v, curr_settings)
                        # ì—¬ê¸°ì„œëŠ” cv_key ë³€ê²½ ì—†ì´ rerun -> ê¹œë¹¡ì„ ì—†ìŒ
                        st.rerun()
                with c3:
                    if st.button("ğŸ—‘ï¸", key=f"del_{i}"):
                        delete_occurred = True
                        continue
                zones_to_keep.append(z)

            if delete_occurred:
                curr_settings['zones'] = zones_to_keep
                save_settings(sel_v, curr_settings)
                st.session_state['cv_key'] += 1  # ì‚­ì œëŠ” ë¦¬ë¡œë“œ í•„ìš”
                st.rerun()

    # --- [íƒ­ 2] ê°ë„ ì„¤ì • ---
    with tab2:
        st.subheader("ê²½ê³ /ìœ„í—˜ íŒë‹¨ ê¸°ì¤€")
        wd = st.slider("âš ï¸ ê²½ê³  ê°ì§€ ê±°ë¦¬ (í”½ì…€)", 0, 200, curr_settings.get('warning_distance', 30))
        et = st.slider("íŒ” ë»—ìŒ ë¹„ìœ¨ (Extension)", 0.5, 1.0, curr_settings['extension_threshold'])
        at = st.slider("íŒ” ê°ë„ ì„ê³„ê°’ (Angle)", 90, 180, curr_settings['angle_threshold'])
        md = st.radio("íŒë‹¨ ëª¨ë“œ", ["Algorithm", "AI", "Both"],
                      index=["Algorithm", "AI", "Both"].index(curr_settings['detection_mode']))

        if st.button("ê°ë„ ì €ì¥"):
            curr_settings.update(
                {'warning_distance': wd, 'extension_threshold': et, 'angle_threshold': at, 'detection_mode': md})
            save_settings(sel_v, curr_settings)
            st.success("ì €ì¥ë¨")

    # --- [íƒ­ 3] ì‹œê°í™” ì„¤ì • ---
    with tab3:
        st.subheader("í™”ë©´ í‘œì‹œ ì˜µì…˜")
        vo = curr_settings['vis_options']
        check_alert = st.checkbox("ğŸš¨ ìœ„í—˜ ì‹œì—ë§Œ í‘œì‹œ", value=vo['alert_only'])
        v_skel = st.checkbox("ë¼ˆëŒ€ (Skeleton)", value=vo['skeleton'])
        v_zone = st.checkbox("êµ¬ì—­ (Zones)", value=vo['zones'])
        v_box = st.checkbox("ê°ì²´ ë°•ìŠ¤ (BBox)", value=vo['bbox'])
        v_dot = st.checkbox("ì†ëª© ì  (Dot)", value=vo['wrist_dot'])
        v_txt = st.checkbox("ìƒíƒœ í…ìŠ¤íŠ¸ (Text)", value=vo['text'])

        if st.button("ì‹œê°í™” ì˜µì…˜ ì €ì¥"):
            vo.update(
                {'alert_only': check_alert, 'skeleton': v_skel, 'zones': v_zone, 'bbox': v_box, 'wrist_dot': v_dot,
                 'text': v_txt})
            save_settings(sel_v, curr_settings)
            st.success("ì €ì¥ë¨")

# ==========================================
# [ì˜¤ë¥¸ìª½] ëª¨ë‹ˆí„°ë§ í™”ë©´
# ==========================================
with right_col:
    st.subheader("ğŸ“¹ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§")
    col_p1, col_p2 = st.columns([3, 1])
    with col_p2:
        run_monitor = st.checkbox("â–¶ ì¬ìƒ", value=True)
    with col_p1:
        cap = cv2.VideoCapture(video_path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        frame_idx = st.slider("íƒìƒ‰", 0, total_frames, 0, label_visibility="collapsed")

    st_screen = st.empty()


    def run_live_processing(frame_img):
        live_settings = curr_settings.copy()
        live_settings['warning_distance'] = wd
        live_settings['extension_threshold'] = et
        live_settings['angle_threshold'] = at
        live_settings['detection_mode'] = md
        live_settings['vis_options'] = {
            'alert_only': check_alert, 'skeleton': v_skel, 'zones': v_zone,
            'bbox': v_box, 'label': True, 'wrist_dot': v_dot, 'text': v_txt
        }
        return process_frame(frame_img, yolo_model, custom_model, live_settings)


    if run_monitor:
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                continue
            out_img = run_live_processing(frame)
            st_screen.image(out_img, channels="RGB")
            time.sleep(0.01)
    else:
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()
        if ret:
            out_img = run_live_processing(frame)
            st_screen.image(out_img, channels="RGB")
    cap.release()