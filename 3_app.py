import streamlit as st
import cv2
import numpy as np
import tempfile
import os
import joblib
import pandas as pd
import math
from ultralytics import YOLO


# ê°ë„ ê³„ì‚° í•¨ìˆ˜
def calculate_angle(a, b, c):
    a = np.array(a)
    b = np.array(b)
    c = np.array(c)
    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])
    angle = np.abs(radians * 180.0 / np.pi)
    if angle > 180.0: angle = 360 - angle
    return angle


st.set_page_config(layout="wide", page_title="AI ë®¤ì§€ì—„ ê°€ë“œ (Ratio Logic)")
st.title("ğŸ›ï¸ AI ì „ì‹œí’ˆ ë³´í˜¸ ì‹œìŠ¤í…œ (ë¹„ìœ¨ ê¸°ë°˜ ë†’ì´ ì œì–´)")

col1, col2 = st.columns([1, 2])

with col1:
    st.header("âš™ï¸ ì„¤ì • íŒ¨ë„")

    # 1. êµ¬ì—­ ì„¤ì •
    st.subheader("1. êµ¬ì—­ ì„¤ì •")
    st.info("ë¹¨ê°„ ë°•ìŠ¤ë¥¼ ì „ì‹œí’ˆì— ë§ì¶”ì„¸ìš”.")
    zone_x = st.slider("ê°€ë¡œ ìœ„ì¹˜ (X)", 0.0, 1.0, 0.4, 0.01)
    zone_y = st.slider("ì„¸ë¡œ ìœ„ì¹˜ (Y)", 0.0, 1.0, 0.5, 0.01)
    zone_w = st.slider("ë„ˆë¹„ (Width)", 0.05, 0.8, 0.15, 0.01)
    zone_h = st.slider("ë†’ì´ (Height)", 0.05, 0.8, 0.25, 0.01)
    padding = st.slider("ê²½ê³„ì˜ì—­ í™•ì¥ (Padding)", 0, 150, 50)

    st.markdown("---")

    # 2. ë¯¼ê°ë„ ì„¤ì •
    st.subheader("2. ë™ì‘ ë¯¼ê°ë„")

    # [ìš”ì²­ 1] ê°ë„ ìµœì†Œê°’ 0ìœ¼ë¡œ ì¡°ì •
    angle_threshold = st.slider(
        "ğŸ’ª íŒ” í´ì§ ê°ë„ (ë‚®ì„ìˆ˜ë¡ ë¯¼ê°)",
        min_value=0, max_value=180, value=120,
        help="0ë„ì— ê°€ê¹Œìš°ë©´ íŒ”ì„ êµ½í˜€ë„ ê°ì§€, 180ë„ë©´ ì™„ì „íˆ í´ì•¼ ê°ì§€"
    )

    # [ìš”ì²­ 2] í”½ì…€ ëŒ€ì‹  ë¹„ìœ¨ ì‚¬ìš©
    st.subheader("3. ë†’ì´ í•„í„° (ë¹„ìœ¨ ê¸°ë°˜)")
    st.info("ì†ì´ 'í•˜ëŠ˜ìƒ‰ ì„ ' ì•„ë˜ì— ìˆìœ¼ë©´ ë¬´ì¡°ê±´ ì•ˆì „í•©ë‹ˆë‹¤.")

    hip_ratio = st.slider(
        "ì•ˆì „ ë†’ì´ ì¡°ì ˆ (ê³¨ë°˜ ê¸°ì¤€)",
        min_value=-0.5, max_value=1.0, value=0.2, step=0.1,
        help="0.0=ê³¨ë°˜ë†’ì´, 0.5=ë°°ê¼½ë†’ì´, 1.0=ì–´ê¹¨ë†’ì´. (ì´ ê°’ë³´ë‹¤ ì•„ë˜ë©´ ë¬´ì‹œ)"
    )

    uploaded_file = st.file_uploader("CCTV ì˜ìƒ ì—…ë¡œë“œ", type=["mp4", "avi"])

if uploaded_file is not None:
    # ëª¨ë¸ ë¡œë“œ
    if os.path.exists('model.pkl'):
        custom_model = joblib.load('model.pkl')
    else:
        st.error("model.pkl íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    try:
        yolo_model = YOLO('yolov8n-pose.pt')
    except:
        st.error("YOLO ë¡œë“œ ì‹¤íŒ¨")
        st.stop()

    tfile = tempfile.NamedTemporaryFile(delete=False)
    tfile.write(uploaded_file.read())
    cap = cv2.VideoCapture(tfile.name)

    with col2:
        st.header("ğŸ“¹ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§")
        st_frame = st.empty()

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                continue

            frame = cv2.resize(frame, (800, 600))
            h, w, _ = frame.shape

            # êµ¬ì—­ ì¢Œí‘œ
            d_x1, d_y1 = int(zone_x * w), int(zone_y * h)
            d_x2, d_y2 = int((zone_x + zone_w) * w), int((zone_y + zone_h) * h)
            w_x1, w_y1 = max(0, d_x1 - padding), max(0, d_y1 - padding)
            w_x2, w_y2 = min(w, d_x2 + padding), min(h, d_y2 + padding)

            results = yolo_model(frame, verbose=False, conf=0.5)
            annotated_frame = results[0].plot()
            image = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)

            global_status = "SAFE"
            overlay_color = None
            is_danger = False
            is_warning = False

            if results[0].keypoints is not None:
                keypoints_data = results[0].keypoints.data.cpu().numpy()

                for kps in keypoints_data:
                    arms = [
                        {'side': 'Right', 's': 6, 'e': 8, 'w': 10, 'h': 12},
                        {'side': 'Left', 's': 5, 'e': 7, 'w': 9, 'h': 11}
                    ]

                    for arm in arms:
                        if len(kps) <= arm['h']: continue

                        s, e, w_pt, h_pt = kps[arm['s']], kps[arm['e']], kps[arm['w']], kps[arm['h']]

                        if w_pt[2] < 0.5: continue  # ì†ëª© ì¸ì‹ ì‹¤íŒ¨ ì‹œ íŒ¨ìŠ¤

                        wx, wy = int(w_pt[0]), int(w_pt[1])
                        ex, ey = int(e[0]), int(e[1])
                        sx, sy = int(s[0]), int(s[1])  # ì–´ê¹¨ Y
                        hx, hy = int(h_pt[0]), int(h_pt[1])  # ê³¨ë°˜ Y

                        # ========================================================
                        # [í•µì‹¬] ë¹„ìœ¨ ê¸°ë°˜ ë†’ì´ í•„í„° (Ratio Height Filter)
                        # ========================================================
                        # 1. ëª¸í†µ ê¸¸ì´ ê³„ì‚° (ì–´ê¹¨ ~ ê³¨ë°˜)
                        torso_height = abs(hy - sy)

                        # 2. ì•ˆì „ ê¸°ì¤€ì„ (Threshold) ê³„ì‚°
                        # ê³¨ë°˜ ìœ„ì¹˜(hy)ì—ì„œ ëª¸í†µ ê¸¸ì´ * ë¹„ìœ¨ë§Œí¼ ìœ„(-)ë¡œ ì˜¬ë¼ê°„ ì§€ì 
                        # ì˜ˆ: ë¹„ìœ¨ 0.2ë©´ ê³¨ë°˜ë³´ë‹¤ ëª¸í†µì˜ 20%ë§Œí¼ ë†’ì€ ê³³
                        safe_y_limit = hy - (torso_height * hip_ratio)

                        # 3. ì†ì˜ ìœ„ì¹˜ íŒë‹¨ (Yê°€ í´ìˆ˜ë¡ ì•„ë˜ìª½)
                        # ì†ëª©Y(wy)ê°€ ê¸°ì¤€ì„ (safe_y_limit)ë³´ë‹¤ í¬ë©´(ì•„ë˜ë©´) ì•ˆì „
                        is_hand_low = wy > safe_y_limit

                        # ì‹œê°í™”: ê¸°ì¤€ì„ ì„ í•˜ëŠ˜ìƒ‰ìœ¼ë¡œ ê·¸ë ¤ì¤Œ (ë””ë²„ê¹…ìš©)
                        if arm['side'] == 'Right':  # í•œ ë²ˆë§Œ ê·¸ë¦¬ê¸° ìœ„í•´
                            cv2.line(image, (hx - 40, int(safe_y_limit)), (hx + 40, int(safe_y_limit)), (255, 255, 0),
                                     2)
                            cv2.putText(image, "Safe Limit", (hx + 45, int(safe_y_limit)), cv2.FONT_HERSHEY_SIMPLEX,
                                        0.4, (255, 255, 0), 1)

                        # ========================================================

                        # AI ì˜ˆì¸¡
                        input_data = pd.DataFrame([{
                            'rw_x': wx / w, 'rw_y': wy / h, 're_x': ex / w, 're_y': ey / h, 'rs_x': sx / w,
                            'rs_y': sy / h
                        }])
                        ai_pred = custom_model.predict(input_data)[0]

                        # ê°ë„ ê³„ì‚°
                        elbow_angle = calculate_angle((sx, sy), (ex, ey), (wx, wy))

                        # ìµœì¢… íŒë‹¨:
                        # (ê°ë„ ë§Œì¡±) AND (AI ë»—ìŒ) AND (ì†ì´ ê¸°ì¤€ì„ ë³´ë‹¤ ë†’ìŒ!)
                        is_reaching = (elbow_angle > angle_threshold) and (ai_pred == 1) and (not is_hand_low)

                        # ìƒíƒœ í…ìŠ¤íŠ¸
                        status_msg = "Low" if is_hand_low else ("Reach" if is_reaching else "Safe")
                        t_color = (200, 200, 200) if is_hand_low else ((0, 0, 255) if is_reaching else (0, 255, 0))
                        cv2.putText(image, status_msg, (wx, wy - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, t_color, 1)

                        in_danger = (d_x1 < wx < d_x2) and (d_y1 < wy < d_y2)
                        in_warning = (w_x1 < wx < w_x2) and (w_y1 < wy < w_y2)

                        if in_danger:
                            # 1ìˆœìœ„: ë¹¨ê°„ ë°•ìŠ¤ ì ‘ì´‰ (ë¬´ì¡°ê±´ ìœ„í—˜)
                            is_danger = True
                            cv2.circle(image, (wx, wy), 20, (255, 0, 0), -1)
                            cv2.putText(image, "TOUCH!", (wx, wy - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)

                        elif in_warning:
                            # 2ìˆœìœ„: ë…¸ë€ êµ¬ì—­ + ë»—ìŒ ê°ì§€
                            if is_reaching:
                                is_warning = True
                                cv2.circle(image, (wx, wy), 15, (255, 165, 0), -1)
                                cv2.putText(image, "REACHING", (wx, wy - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.6,
                                            (255, 165, 0), 2)
                            else:
                                cv2.circle(image, (wx, wy), 8, (0, 0, 255), -1)  # íŒŒë€ì 

            if is_danger:
                global_status = "DANGER (TOUCH)"
                overlay_color = (255, 0, 0)
            elif is_warning:
                global_status = "WARNING (APPROACH)"
                overlay_color = (255, 165, 0)

            cv2.rectangle(image, (w_x1, w_y1), (w_x2, w_y2), (255, 255, 0), 2)
            cv2.rectangle(image, (d_x1, d_y1), (d_x2, d_y2), (255, 0, 0), 3)

            if overlay_color:
                cv2.putText(image, global_status, (50, 300), cv2.FONT_HERSHEY_SIMPLEX, 1.5, overlay_color, 4)

            cv2.rectangle(image, (0, 0), (800, 50), (0, 0, 0), -1)
            cv2.putText(image, f"SYSTEM: {global_status}", (20, 35), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)

            st_frame.image(image, channels="RGB")

    cap.release()

    # streamlit run 3_app.py