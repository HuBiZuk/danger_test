# main.py

import streamlit as st
import cv2
import os
import time

# ëª¨ë“ˆ ì„í¬íŠ¸
import utils
import processor
import view

# 1. ì´ˆê¸°í™” ë° ì„¤ì •
st.set_page_config(layout="wide", page_title="AI ì „ì‹œí’ˆ ë³´í˜¸ ì‹œìŠ¤í…œ v3")
utils.init_directories()

# utils.apply_streamlit_patch()  # ì´ë¯¸ì§€ í˜¸í™˜ì„± íŒ¨ì¹˜ ì ìš© - Streamlit 1.22.0ì—ì„œëŠ” í•„ìš” ì—†ìœ¼ë¯€ë¡œ ì œê±° ë˜ëŠ” ì£¼ì„ ì²˜ë¦¬

st.title("ğŸ›ï¸ AI ì „ì‹œí’ˆ ë³´í˜¸ ê´€ë¦¬ ì‹œìŠ¤í…œ")

# 2. ì‚¬ì´ë“œë°” (íŒŒì¼ ì„ íƒ)
sel_v, sel_model_name = view.render_sidebar()

# 3. ëª¨ë¸ ë¡œë“œ
yolo_model, custom_model, fire_model = processor.get_models(sel_model_name)

if not sel_v or not yolo_model:
    st.warning("ì˜ìƒì„ ì„ íƒí•˜ê±°ë‚˜ ëª¨ë¸ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# 4. ì„¤ì • ë¡œë“œ
video_path = os.path.join("videos", sel_v)
curr_settings = utils.load_settings(sel_v)

# 5. ë©”ì¸ ë ˆì´ì•„ì›ƒ (ì¢Œìš° ë¶„í• )
left_col, right_col = st.columns([1, 1], gap="medium")

# --- [ì™¼ìª½] ì„¤ì • ë° í¸ì§‘ í™”ë©´ ---
with left_col:
    # st.tabsëŠ” Streamlit 1.22.0ì—ì„œ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. st.radioë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.
    selected_tab = st.radio(
        "ì„¤ì • íƒ­ ì„ íƒ",
        ["ğŸ“ êµ¬ì—­ ê´€ë¦¬", "âš¡ ê°ë„ ì„¤ì •", "ğŸ‘ï¸ ì‹œê°í™” ì„¤ì •"],
        key="main_tabs",
        horizontal=True # íƒ­ì²˜ëŸ¼ ë³´ì´ê²Œ í•˜ê¸° ìœ„í•´ ê°€ë¡œ ì •ë ¬
    )

    if selected_tab == "ğŸ“ êµ¬ì—­ ê´€ë¦¬":
        view.render_zone_tab(sel_v, curr_settings, video_path)
    elif selected_tab == "âš¡ ê°ë„ ì„¤ì •":
        wd, et, at, md, hr, fire_check, fall_check, fr, ai_th = view.render_sensitivity_tab(sel_v, curr_settings)
        st.session_state['wd'] = wd
        st.session_state['et'] = et
        st.session_state['at'] = at
        st.session_state['md'] = md
        st.session_state['hr'] = hr
        st.session_state['fire_check'] = fire_check
        st.session_state['fall_check'] = fall_check
        st.session_state['fr'] = fr
        st.session_state['ai_th'] = ai_th  # ğŸ‘ˆ [ì¶”ê°€] ì„¸ì…˜ì— ì €ì¥


    elif selected_tab == "ğŸ‘ï¸ ì‹œê°í™” ì„¤ì •":
        # render_vis_tabì—ì„œ ë¦¬í„´ê°’ì„ ë°›ì•„ì•¼ í•¨
        check_alert, v_skel, v_zone, v_box, v_dot, v_txt = view.render_vis_tab(sel_v, curr_settings)
        st.session_state['check_alert'] = check_alert
        st.session_state['v_skel'] = v_skel
        st.session_state['v_zone'] = v_zone
        st.session_state['v_box'] = v_box
        st.session_state['v_dot'] = v_dot
        st.session_state['v_txt'] = v_txt


# --- [ì˜¤ë¥¸ìª½] ëª¨ë‹ˆí„°ë§ í™”ë©´ ---
with right_col:
    st.subheader("ğŸ“¹ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§")

    col_p1, col_p2 = st.columns([3, 1])
    with col_p2:
        run_monitor = st.checkbox("â–¶ ì¬ìƒ", value=True)
    with col_p1:
        cap = cv2.VideoCapture(video_path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        # st.sliderì˜ label_visibilityëŠ” Streamlit 1.22.0ì—ì„œ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        frame_idx = st.slider("íƒìƒ‰", 0, total_frames, 0) # label=""ë¡œ ë ˆì´ë¸” ëª…ì‹œì  ì œê±°


    st_screen = st.empty()

    # ì‹¤ì‹œê°„ ì„¤ì •ì„ ë°˜ì˜í•˜ê¸° ìœ„í•œ ë”•ì…”ë„ˆë¦¬ êµ¬ì„±
    live_settings = curr_settings.copy()

    live_settings['warning_distance'] = st.session_state.get('wd', curr_settings.get("warning_distance", 30))
    live_settings['extension_threshold'] = st.session_state.get('et', curr_settings.get("extension_threshold", 0.7))
    live_settings['angle_threshold'] = st.session_state.get('at', curr_settings.get("angle_threshold", 120))
    live_settings['detection_mode'] = st.session_state.get('md', curr_settings.get("detection_mode", "Algorithm"))
    live_settings['hip_ratio'] = st.session_state.get('hr', curr_settings.get("hip_ratio", 0.2))
    live_settings['fire_check'] = st.session_state.get('fire_check', curr_settings.get("fire_check", False))
    live_settings['fall_check'] = st.session_state.get('fall_check', curr_settings.get("fall_check", True))
    live_settings['fall_ratio'] = st.session_state.get('fr', curr_settings.get("fall_ratio", 1.2))
    live_settings['ai_threshold'] = st.session_state.get('ai_th', curr_settings.get("ai_threshold", 0.7))




    live_settings['vis_options'] = curr_settings.get('vis_options', {
        'alert_only': False, 'skeleton': True, 'zones': True,
        'bbox': True, 'label': True, 'wrist_dot': True, 'text': True
    })
    live_settings['vis_options']['alert_only'] = st.session_state.get('check_alert', live_settings['vis_options']['alert_only'])
    live_settings['vis_options']['skeleton'] = st.session_state.get('v_skel', live_settings['vis_options']['skeleton'])
    live_settings['vis_options']['zones'] = st.session_state.get('v_zone', live_settings['vis_options']['zones'])
    live_settings['vis_options']['bbox'] = st.session_state.get('v_box', live_settings['vis_options']['bbox'])
    live_settings['vis_options']['wrist_dot'] = st.session_state.get('v_dot', live_settings['vis_options']['wrist_dot'])
    live_settings['vis_options']['text'] = st.session_state.get('v_txt', live_settings['vis_options']['text'])


    # ì¬ìƒ ë£¨í”„
    if run_monitor:
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # ë¬´í•œ ë°˜ë³µ
                continue

            # processor ëª¨ë“ˆì— ìœ„ì„
            out_img = processor.process_frame(frame, yolo_model, custom_model, fire_model, live_settings)
            st_screen.image(out_img, channels="RGB")

            time.sleep(0.01)  # CPU ì ìœ ìœ¨ ì¡°ì ˆ
    else:
        # ì¼ì‹œ ì •ì§€ ìƒíƒœ
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()
        if ret:
            out_img = processor.process_frame(frame, yolo_model, custom_model, fire_model, live_settings)
            st_screen.image(out_img, channels="RGB")

    cap.release()

    # streamlit run main.py