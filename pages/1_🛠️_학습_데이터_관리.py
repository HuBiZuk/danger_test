import streamlit as st
import pandas as pd
import numpy as np
import os
import joblib
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

# ìƒìœ„ í´ë” ëª¨ë“ˆ ê²½ë¡œ ì„¤ì •
import sys

sys.path.append(os.path.dirname(os.path.abspath(__file__)) + "/..")

import data_augmenter  # ë°ì´í„° ì¦ê°• ëª¨ë“ˆ

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(layout="wide", page_title="í•™ìŠµ ë°ì´í„° ê´€ë¦¬")
st.title("ğŸ› ï¸ AI í•™ìŠµ ë°ì´í„° ê´€ë¦¬ ë° ëª¨ë¸ í›ˆë ¨")


# -------------------------------------------------------------------------
# [í•µì‹¬ í•¨ìˆ˜] í”½ì…€ ì¢Œí‘œ -> ì‹ ì²´ ë¹„ìœ¨(Ratio) ë³€í™˜
# -------------------------------------------------------------------------
def convert_to_ratio(df):
    """
    ì ˆëŒ€ ì¢Œí‘œ(í”½ì…€)ë¡œ ëœ ë°ì´í„°ë¥¼ ëª¸í†µ í¬ê¸° ê¸°ì¤€ ë¹„ìœ¨ ë°ì´í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    - í•´ìƒë„, ê±°ë¦¬, ì²´ê²© ì°¨ì´ë¥¼ ì—†ì• ì¤ë‹ˆë‹¤.
    """
    # ì¢Œí‘œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
    v_cols = [c for c in df.columns if c.startswith('v')]
    meta_cols = [c for c in df.columns if c not in v_cols]

    if not v_cols: return df

    coords = df[v_cols].values
    new_coords_list = []

    for row in coords:
        # 17ê°œ ê´€ì ˆ, 2ê°œ ì¢Œí‘œ(x,y)ë¡œ êµ¬ì¡°í™”
        # í–‰ í•˜ë‚˜ë¥¼ (-1, 17, 2)ë¡œ reshapeí•˜ë©´ [í”„ë ˆì„ìˆ˜, 17ê°œê´€ì ˆ, 2ì¢Œí‘œ]ê°€ ë¨
        try:
            frames = row.reshape(-1, 17, 2)
        except ValueError:
            # ì»¬ëŸ¼ ê°œìˆ˜ê°€ 17*2ì˜ ë°°ìˆ˜ê°€ ì•„ë‹ˆë©´ ë³€í™˜ ë¶ˆê°€ (ê·¸ëŒ€ë¡œ ë°˜í™˜)
            return df

        normalized_frames = []

        for frame in frames:
            # frame shape: (17, 2)
            # 5:ì™¼ì–´ê¹¨, 6:ì˜¤ë¥¸ì–´ê¹¨, 11:ì™¼ê³¨ë°˜, 12:ì˜¤ë¥¸ê³¨ë°˜

            # 1. ê³¨ë°˜ ì¤‘ì‹¬ì  (0,0 ê¸°ì¤€ì )
            l_hip = frame[11]
            r_hip = frame[12]
            center = (l_hip + r_hip) / 2

            # 2. ì²™ì¶” ê¸¸ì´ (ëª¸í†µ í¬ê¸°) ê³„ì‚° = ìŠ¤ì¼€ì¼ ê¸°ì¤€
            l_sh = frame[5]
            r_sh = frame[6]
            center_sh = (l_sh + r_sh) / 2

            # ëª¸í†µ ê¸¸ì´ (ê³¨ë°˜~ì–´ê¹¨ ê±°ë¦¬)
            torso_size = np.linalg.norm(center_sh - center)

            # 3. í¬ê¸° ì •ê·œí™” (ëª¸í†µ í¬ê¸°ë¥¼ 1.0ìœ¼ë¡œ ë§ì¶¤)
            # ì´ë¯¸ ë¹„ìœ¨ ë°ì´í„°ê±°ë‚˜ ë…¸ì´ì¦ˆì¸ ê²½ìš°(í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŒ)ëŠ” 1.0ìœ¼ë¡œ ì²˜ë¦¬í•´ ì—ëŸ¬ ë°©ì§€
            scale = torso_size if torso_size > 10 else 1.0

            # ë³€í™˜ ê³µì‹: (ë‚´ì¢Œí‘œ - ì¤‘ì‹¬ì ) / ëª¸í†µê¸¸ì´
            norm_frame = (frame - center) / scale
            normalized_frames.append(norm_frame)

        # ë‹¤ì‹œ 1ì¤„ë¡œ í´ê¸°
        new_row = np.array(normalized_frames).flatten()
        new_coords_list.append(new_row)

    # ë°ì´í„°í”„ë ˆì„ ì¬êµ¬ì„±
    df_new = pd.DataFrame(new_coords_list, columns=v_cols)
    df_meta = df[meta_cols]  # ë©”íƒ€ë°ì´í„° ìœ ì§€

    # ì¸ë±ìŠ¤ ë¦¬ì…‹ í›„ ë³‘í•©
    df_new.reset_index(drop=True, inplace=True)
    df_meta.reset_index(drop=True, inplace=True)

    return pd.concat([df_new, df_meta], axis=1)


# í™”ë©´ ë¶„í• 
left_col, right_col = st.columns([1, 1], gap="large")

# ==============================================================================
# [ì™¼ìª½] ë°ì´í„° ì¦ê°• ë„êµ¬ (ë¹„ìœ¨ ë³€í™˜ ê¸°ëŠ¥ í¬í•¨)
# ==============================================================================
with left_col:
    st.subheader("1ï¸âƒ£ ë°ì´í„° ì¦ê°• (Augmentation)")
    st.info("ì›ë³¸ CSVë¥¼ ì—…ë¡œë“œí•˜ë©´ 'ë¹„ìœ¨ ë°ì´í„°'ë¡œ ë³€í™˜ í›„ ì¦ê°•í•©ë‹ˆë‹¤.")

    uploaded_file = st.file_uploader("ì›ë³¸ ë°ì´í„°(CSV) ì—…ë¡œë“œ", type=["csv"])

    if uploaded_file:
        try:
            df_origin = pd.read_csv(uploaded_file)
        except UnicodeDecodeError:
            uploaded_file.seek(0)
            df_origin = pd.read_csv(uploaded_file, encoding='cp949')
        except Exception as e:
            st.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            st.stop()

        st.write(f"ğŸ“‚ ì›ë³¸ ë°ì´í„°: **{len(df_origin)}** í–‰")

        st.markdown("##### âš™ï¸ í´ë˜ìŠ¤ë³„ ì¦ê°• ë°°ìœ¨ ì„¤ì •")
        col_n, col_m, col_t = st.columns(3)
        with col_n:
            n_fac = st.number_input("Neutral (ì •ì§€)", min_value=1, value=1)
        with col_m:
            m_fac = st.number_input("Movement (ì´ë™)", min_value=1, value=2)
        with col_t:
            t_fac = st.number_input("Threat (ìœ„í˜‘)", min_value=1, value=10)

        # ğŸš€ ì¦ê°• ì‹¤í–‰ ë²„íŠ¼
        if st.button("ğŸš€ ë³€í™˜ ë° ì¦ê°• ì‹¤í–‰", type="primary"):
            try:
                with st.spinner("1ë‹¨ê³„: ì‹ ì²´ ë¹„ìœ¨ ë°ì´í„°ë¡œ ë³€í™˜ ì¤‘..."):
                    # ğŸ‘‡ [í•µì‹¬] ì—¬ê¸°ì„œ ë¹„ìœ¨ ë³€í™˜ í•¨ìˆ˜ í˜¸ì¶œ
                    df_ratio = convert_to_ratio(df_origin)

                with st.spinner("2ë‹¨ê³„: ë°ì´í„° ì¦ê°• ì²˜ë¦¬ ì¤‘..."):
                    # ë³€í™˜ëœ df_ratioë¥¼ ë„£ì–´ì„œ ì¦ê°• ìˆ˜í–‰
                    df_aug = data_augmenter.run_augmentation(
                        df_ratio,
                        neutral_factor=n_fac,
                        movement_factor=m_fac,
                        threat_factor=t_fac
                    )

                    # íŒŒì¼ ì €ì¥ (íŒŒì¼ëª…ì— ratio_aug_ ë¶™ì„)
                    save_name = f"ratio_aug_{uploaded_file.name}"
                    df_aug.to_csv(save_name, index=False)

                    st.success(f"âœ… ì‘ì—… ì™„ë£Œ! ì´ **{len(df_aug)}** í–‰")
                    st.success(f"ì €ì¥ë¨: `{save_name}`")

                    with st.expander("ê²°ê³¼ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ê°’ ë²”ìœ„ë¥¼ í™•ì¸í•˜ì„¸ìš”)"):
                        st.dataframe(df_aug.head())
                        st.caption("â€» ê°’ì´ -1.5 ~ 1.5 ì‚¬ì´ì˜ ì†Œìˆ˜ì ì´ë©´ ë¹„ìœ¨ ë³€í™˜ì´ ì˜ ëœ ê²ƒì…ë‹ˆë‹¤.")

            except Exception as e:
                st.error(f"ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ==============================================================================
# [ì˜¤ë¥¸ìª½] ëª¨ë¸ í•™ìŠµ ë„êµ¬
# ==============================================================================
with right_col:
    st.subheader("2ï¸âƒ£ ëª¨ë¸ í•™ìŠµ (Training)")
    st.info("ì¦ê°•ëœ ë°ì´í„°('ratio_aug_...')ë¥¼ ì„ íƒí•˜ì—¬ í•™ìŠµí•˜ì„¸ìš”.")

    # íŒŒì¼ ëª©ë¡ (ratio_aug_ë¡œ ì‹œì‘í•˜ëŠ” íŒŒì¼ë§Œ í•„í„°ë§ ì¶”ì²œ)
    csv_files = [f for f in os.listdir(".") if f.endswith(".csv") and "aug_" in f]

    if not csv_files:
        st.warning("í•™ìŠµí•  ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        target_file = st.selectbox("í•™ìŠµì— ì‚¬ìš©í•  íŒŒì¼ ì„ íƒ", csv_files)

        st.markdown("##### âš™ï¸ í•™ìŠµ íŒŒë¼ë¯¸í„°")
        n_estimators = st.slider("íŠ¸ë¦¬ ê°œìˆ˜ (Estimators)", 10, 200, 100)

        if st.button("ğŸ”¥ ëª¨ë¸ í•™ìŠµ ì‹œì‘", type="primary"):
            try:
                with st.spinner(f"'{target_file}' ë¡œë”© ì¤‘..."):
                    df_train = pd.read_csv(target_file)

                    feature_cols = [c for c in df_train.columns if c.startswith('v')]
                    X = df_train[feature_cols]
                    y = df_train['label']

                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

                with st.spinner("AI ëª¨ë¸ í•™ìŠµ ì¤‘..."):
                    model = RandomForestClassifier(n_estimators=n_estimators, random_state=0)

                    # 1ì°¨ì› ë°°ì—´ ë³€í™˜ (ê²½ê³  ë°©ì§€)
                    model.fit(X_train, y_train.values.ravel())

                    y_pred = model.predict(X_test)
                    acc = accuracy_score(y_test, y_pred)

                st.success(f"ğŸ‰ í•™ìŠµ ì™„ë£Œ! ì •í™•ë„: **{acc * 100:.2f}%**")

                # ëª¨ë¸ ì €ì¥
                model_save_path = "model.pkl"
                joblib.dump(model, model_save_path)
                real_path = os.path.abspath(model_save_path)

                st.success(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ! ìœ„ì¹˜: `{real_path}`")

                with st.expander("ìƒì„¸ ê²°ê³¼ ë³´ê³ ì„œ"):
                    report = classification_report(y_test, y_pred, output_dict=True)
                    st.json(report)

            except Exception as e:
                st.error(f"í•™ìŠµ ì˜¤ë¥˜: {e}")